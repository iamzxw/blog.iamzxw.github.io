---
layout:     post   				    # 使用的布局（不需要改）
title:     	深度学习 / 图像分类 / PolyNet 论文笔记
subtitle:      #副标题
date:       2018-9-25 				# 时间
author:     zhu.xinwei 		    	# 作者
header-img: img/post-bg-desk.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - PolyNet
    - SenseTime
    - ILSVRC 2016
---

> [PolyNet:A Pursuit of Structural Diversity in Very Deep Networks](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_PolyNet_A_Pursuit_CVPR_2017_paper.pdf)
是香港中文大学发表在CVPR2017上的一篇论文。 作者从结构多样性(structural diversity的角度出发，探索模型架构设计)。

回顾，在网络结构设计的发展中，存在着几个关键的路线：
- 在网络深度／宽度上进行增强【AlexNet-->VGG-->ResNet，GoogleNet】
- 深度，宽度相互借鉴【ResNeXt，Iception ResNet】
- 在卷积核上进行处理：width/height/channel解耦合【1xn，nx1，1x1，depthwise-separable conv, Inception V4, Xception】
- 多样性：structural diversity【Inception module】

一些洞见：
- 集成方案通常优于任意单独网络
- ResNet可视为浅层网络的隐式集成(有工作证明：成功源自多样性而非深度)；
- Inception-ResNet-v2取得了更好的性能，相比ResNet，它具有更少的层。

所有发现均暗示：多样性(深度网络设计中的一个关键因素)值得进行系统研究。

___
### PolyNet

整个网络建立在Inception-ResNet-v2的整体结构基础上，对其中的Inception模块进行了改进。 将Inception-ResNet-v2中A，B，C模块替换为PolyInception基础模块

#### PolyInception

![](/img/cnn/polynet/residual_unit.PNG)

ResNet，Inception_ResNet中的残差模块很浅, 仅包含2-4个卷积层，限制了每个单元的容量和多样性，所以可以再多加入一些单元构建更好的表现性能。

![](/img/cnn/polynet/poly_inception.PNG)

采用多项式组合方式泛化加性组合操作, 添加二次项。

有三种通道形式：等价通路、一阶通路以及二阶通路。所有通路的结果进行相加得到该单元的输出(相加后再ReLU)。二阶通路允许输入信号在被合并到主路径之前通过更深的变换。这可以提升单元的表现性能。


- Poly-2：,它包含两种形式。这种方式意味着他们共享参数。这种设计可以提升表现性能而不会引入额外参数；
- Mpoly-2：，这种架构类似于poly-2，区别在于两个Inception模块不共享参数。它具有更强的表现性能，但会造成参数增加。
- 2-way：，这是一种一阶PolyInception，它集成额外的一阶通路到整个单元中。这种构架类似于Multiple Residual Network。


```python

```

和其他网络结构类似，在进入主卷积模块之前，先有个Stem卷积。

```python

class Stem(nn.Module):

    def __init__(self):
        super(Stem, self).__init__()
        self.conv1 = nn.Sequential(
            BasicConv2d(3, 32, kernel_size=3, stride=2),
            BasicConv2d(32, 32, kernel_size=3),
            BasicConv2d(32, 64, kernel_size=3, padding=1),
        )
        self.conv1_pool_branch = nn.MaxPool2d(3, stride=2)
        self.conv1_branch = BasicConv2d(64, 96, kernel_size=3, stride=2)
        self.conv2_short = nn.Sequential(
            BasicConv2d(160, 64, kernel_size=1),
            BasicConv2d(64, 96, kernel_size=3),
        )
        self.conv2_long = nn.Sequential(
            BasicConv2d(160, 64, kernel_size=1),
            BasicConv2d(64, 64, kernel_size=(7, 1), padding=(3, 0)),
            BasicConv2d(64, 64, kernel_size=(1, 7), padding=(0, 3)),
            BasicConv2d(64, 96, kernel_size=3),
        )
        self.conv2_pool_branch = nn.MaxPool2d(3, stride=2)
        self.conv2_branch = BasicConv2d(192, 192, kernel_size=3, stride=2)

    def forward(self, x):
        x = self.conv1(x)

        x0 = self.conv1_pool_branch(x)
        x1 = self.conv1_branch(x)
        x = torch.cat((x0, x1), 1)

        x0 = self.conv2_short(x)
        x1 = self.conv2_long(x)
        x = torch.cat((x0, x1), 1)

        x0 = self.conv2_pool_branch(x)
        x1 = self.conv2_branch(x)
        out = torch.cat((x0, x1), 1)
        return out

```



```python

class PolyNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(PolyNet, self).__init__()
        self.stem = Stem()
        self.stage_a = nn.Sequential(
            InceptionResNetA2Way(scale=1),
            InceptionResNetA2Way(scale=0.992308),
            InceptionResNetA2Way(scale=0.984615),
            InceptionResNetA2Way(scale=0.976923),
            InceptionResNetA2Way(scale=0.969231),
            InceptionResNetA2Way(scale=0.961538),
            InceptionResNetA2Way(scale=0.953846),
            InceptionResNetA2Way(scale=0.946154),
            InceptionResNetA2Way(scale=0.938462),
            InceptionResNetA2Way(scale=0.930769),
        )
        self.reduction_a = ReductionA()
        self.stage_b = nn.Sequential(
            InceptionResNetBPoly3(scale=0.923077),
            InceptionResNetB2Way(scale=0.915385),
            InceptionResNetBPoly3(scale=0.907692),
            InceptionResNetB2Way(scale=0.9),
            InceptionResNetBPoly3(scale=0.892308),
            InceptionResNetB2Way(scale=0.884615),
            InceptionResNetBPoly3(scale=0.876923),
            InceptionResNetB2Way(scale=0.869231),
            InceptionResNetBPoly3(scale=0.861538),
            InceptionResNetB2Way(scale=0.853846),
            InceptionResNetBPoly3(scale=0.846154),
            InceptionResNetB2Way(scale=0.838462),
            InceptionResNetBPoly3(scale=0.830769),
            InceptionResNetB2Way(scale=0.823077),
            InceptionResNetBPoly3(scale=0.815385),
            InceptionResNetB2Way(scale=0.807692),
            InceptionResNetBPoly3(scale=0.8),
            InceptionResNetB2Way(scale=0.792308),
            InceptionResNetBPoly3(scale=0.784615),
            InceptionResNetB2Way(scale=0.776923),
        )
        self.reduction_b = ReductionB()
        self.stage_c = nn.Sequential(
            InceptionResNetCPoly3(scale=0.769231),
            InceptionResNetC2Way(scale=0.761538),
            InceptionResNetCPoly3(scale=0.753846),
            InceptionResNetC2Way(scale=0.746154),
            InceptionResNetCPoly3(scale=0.738462),
            InceptionResNetC2Way(scale=0.730769),
            InceptionResNetCPoly3(scale=0.723077),
            InceptionResNetC2Way(scale=0.715385),
            InceptionResNetCPoly3(scale=0.707692),
            InceptionResNetC2Way(scale=0.7),
        )
        self.avg_pool = nn.AvgPool2d(9, stride=1)
        self.dropout = nn.Dropout(0.2)
        self.last_linear = nn.Linear(2048, num_classes)

    def features(self, x):
        x = self.stem(x)
        x = self.stage_a(x)
        x = self.reduction_a(x)
        x = self.stage_b(x)
        x = self.reduction_b(x)
        x = self.stage_c(x)
        return x

    def logits(self, x):
        x = self.avg_pool(x)
        x = self.dropout(x)
        x = x.view(x.size(0), -1)
        x = self.last_linear(x)
        return x

    def forward(self, x):
        x = self.features(x)
        x = self.logits(x)
        return x

```



2nd ILSVRC 2016




