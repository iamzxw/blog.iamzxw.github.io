---
layout:     post
title:      深度学习 / 目标检测算法综述 阅读笔记
subtitle:   SIGAI原创,#副标题
date:       2019-6-5 				# 时间
author:     zhu.xinwei 		    	# 作者
header-img: img/post-bg-desk.jpg	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 目标检测
    - R-CNN
    - Fast-RCNN
    - YOLO
---


计算机视觉中关于图像识别有四大类任务：

- **分类-Classification：**解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。

- **定位-Location：**解决“在哪里？”的问题，即定位出这个目标的的位置。

- **检测-Detection：**解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。

- **分割-Segmentation：**分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。

![](/img/cnn/cv_task_4.PNG)


计算机视觉在深度学习方面的应用，主要问题还是数据量不够，而且因为图像的特殊性，似乎无论收集多少标注数据都不够复杂的卷积网络使用。这也是CV任务额模型很容易过拟合的原因：相较于其他ML任务，CV数据量不多，而模型又很复杂。

这四大CV任务的难度也是递增的。分类任务相对简单，但是用于分类各种CNN模型（inception、resnet、resnext、se-net、polynet）已经非常复杂，更不用说后面几个任务了。


**目标检测面临的问题：**

- 目标可能出现在图像的任何位置。

- 目标有各种不同的大小。

- 目标可能有各种不同的形状


如果用**边界框**来定义目标，则边界框有不同的宽高比。由于目标的宽高比不同，因此采用经典的**滑动窗口+图像缩放**的方案解决通用目标检测问题的成本太高。

目标检测的应用领域：行人检测、车辆检测、缺陷检测、害虫识别、医学影像


___
#### 两个预热算法

##### DPM算法

**标签：** 2008年、CVPR、NIPS、蝉联三届PASCAL VOC目标检测冠军、

在深度卷积神经网络（DCNN）出现之前，DPM算法一直是目标检测领域最优秀的算法。

**基本思想**：先提取DPM人工特征，再用latentSVM分类。

**局限性**：首先，DPM特征计算复杂，计算速度慢；其次，人工特征对于旋转、拉伸、视角变化的物体检测效果差。这些弊端很大程度上限制了算法的应用场景。

![](/img/cnn/dpm.PNG)

##### OverFeat

**标签：** 2013年、改进AlexNet、共享卷积层用于多任务学习、全卷积网络、特征层进行滑窗操作

2013年纽约大学Yann LeCun团队中Zhang xiang等提出的OverFeat在ILSVRC2013比赛中获得了多项第一，他们改进了Alexnet，提出了使用同一个卷积网络完成了多个任务的方法。该方法充分利用了卷积神经网络的特征提取功能，它把分类过程中提取到的特征同时又用于定位检测等各种任务，只需要改变网络的最后几层，就可以实现不同的任务，而不需要从头开始训练整个网络的参数。这充分体现和发掘了CNN特征共享的优点。


经典的卷积神经网络有一个问题是它**只能接受固定大小的输入图像**，这是因为第一个**全连接层和它之前的卷积层之间的权重矩阵大小是固定的**，而**卷积层、全连接层本身对输入图像的大小并没有限制**。而在做目标检测时，卷积网络面临的输入候选区域图像大小尺寸是不固定的。

怎么让一个已经设计好的DCNN模型，可以支持任意大小图片输入? 

其中一种方案是**全卷积网络（FCN）**，即去掉所有全连接层，全部由卷积层来替代, 网络最后输出的特征图片大小不再总是1×1而是一个与输入图片大小相关

**局限性**：
- 采用了多尺度贪婪的划窗策略，导致计算量还是很大 。
- 由于当时并没有太优秀的backbone网络，共享特征层的表征能力不是太强，没有考虑多尺度特征融合，对小目标效果差，整体的检测效果不尽如人意。


___
#### 目标检测的DL时代
___
##### Region-CNN


**标签：** 2014年 、 CVPR、 候选取、 

![](/img/cnn/rcnn.PNG)

**R-CNN检测时的主要步骤为：**

1.使用Selective Search算法从待检测图像中提取2000个左右的区域候选框(Regions of Interest RoI)，这些候选框可能包含要检测的目标。

2.把所有侯选框缩放成固定大小（原文采用227×227, Warped image regions）。

3.用DCNN提取每个候选框的特征，得到固定长度的特征向量(Forward each region through ConvNet)。

4.把特征向量送入SVM进行分类得到类别信息，送入全连接网络进行回归得到对应位置坐标信息。

R-CNN不采用滑动窗口方案的原因：
- **计算成本高**，会产生大量的待分类窗口
- **不同类型目标的矩形框有不同的宽高比，无法使用统一尺寸的窗口对图像进行扫描**。

用于提取特征的卷积网络有5个卷积层和2个全连接层(ConvNet)，其输入是固定大小的RGB图像，输出为4096维特征向量。**对候选区域的分类采用线性支持向量机**，对每一张待检测图像计算所有候选区域的特征向量，送入支持向量机中进行分类；同时送入**全连接网络进行坐标位置回归**。


![](/img/cnn/rcnn_2.PNG)

**局限性：**

- 重复计算: R-CNN虽然不再是穷举(滑动窗口法)，但通过Proposal（Selective Search）的方案依然有两千个左右的候选框，这些候选框都需要单独经过backbone网络提取特征，计算量依然很大，候选框之间会有重叠，因此有不少其实是重复计算。

- 训练测试不简洁：候选区域提取、特征提取、分类、回归都是分开操作，中间数据还需要单独保存。

- 速度慢：前面的缺点最终导致R-CNN出奇的慢，GPU上处理一张图片需要十几秒，CPU上则需要更长时间。

- 输入的图片Patch必须强制缩放成固定大小（原文采用227×227），会造成物体形变，导致检测性能下降。


___
##### SPPNet

**标签：**： ECCV 2014、 改进RCNN、 Kaiming He、 空间金字塔池化、特征图上进行候选框特征向量提取

该方法虽然还依赖候选框的生成，但将提取候选框特征向量的操作转移到卷积后的特征图上进行，将R-CNN中的多次卷积变为一次卷积，大大降低了计算量（这一点参考了OverFeat）。

R-CNN的卷积网络只能接受固定大小的输入图像。为了适应这个图像尺寸，要么截取这个尺寸的图像区域，这将导致图像未覆盖整个目标；要么对图像进行缩放，这会产生扭曲。在卷积神经网络中，**卷积层并不要求输入图像的尺寸固定，只有第一个全连接层需要固定尺寸的输入**，因为它和前一层之间的权重矩阵是固定大小的，其他的全连接层也不要求图像的尺寸固定。**如果在最后一个卷积层和第一个全连接层之间做一些处理，将不同大小的特征图变为固定大小的全连接层输入就可以解决问题**。


SPPNet引入了**Spatial Pyramid pooling**层，对卷积特征图像进行空间金字塔采样获得固定长度的输出，可对特征层任意长宽比和尺度区域进行特征提取。具体做法是对特征图像区域进行固定数量的网格划分，对不同宽高的图像，每个网格的高度和宽度是不规定的，对划分的每个网格进行池化，这样就可以得到固定长度的输出。下图是SPP操作示意图：

![](/img/cnn/spp.PNG)


R-CNN和SPPNet 检测流程的比较

![](/img/cnn/spp_2.PNG)

**局限性：** SPPNet和R-CNN一样，它的训练要经过多个阶段，中间特征也要进行存储；backbone网络参数沿用了分类网络的初始参数，没有针对检测问题进行优化


___
##### Fast RCNN

**标签：**： ICCV2015、RoI Pooling

主要创新：
- 兴趣区池化层 RoI Pooling：将不同大小候选框的卷积特征图统一采样成固定大小的特征，做法和空间金字塔池化类似，但是只使用一个尺度进行网络划分和池化。该层可以直接求导，训练时直接将梯度传导到backbone网络进行优化。
- 将深度网络和后面的SVM分类两个阶段整合到一起，使用一个新的网络直接做分类和回归。

![](/img/cnn/fast_rcnn.PNG)

重要的是Fast RCNN的backbone网络也可以参与训练了！！！


___
##### Faster RCNN

**标签：**： 区域候选网络RPN、 

创新点：
- 区域候选网络RPN：在主干网络中增加RPN，通过一定规则在RPN的卷积特征层提取候选框来代替Selective Search等传统的候选框生成方法，候选区域生成、候选区域特征提取、框回归和分类全过程一气呵成

第一个真正意义上的深度学习目标检测算法。

![](/img/cnn/faster_rcnn.PNG)


___
##### R-FCN



