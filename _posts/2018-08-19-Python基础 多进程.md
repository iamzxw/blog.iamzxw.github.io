---
layout:     post   				    # 使用的布局（不需要改）
title:      Python基础 / 多进程 MultiProcessing 学习笔记
subtitle:      #副标题
date:       2018-03-19 				# 时间
author:     zhu.xinwei 		    	# 作者
header-img: img/post-bg-desk.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - Python基础
    - 多进程
    - MultiProcessing
---

概括：

- Unix/Linux操作系统提供了一个fork()系统调用实现多进程创建, python的os模块封装了常见的系统调用，包括fork()函数；

- multiprocessing模块封装了os.fork()调用，使我们不需要关注os.fork()的细节；

- 进程间通信是通过multiprocessing.Queue、Pipes等实现的。

另外:
> multiprocessing模块有这个一句话： This package is intended to duplicate the functionality (and much of the API) of threading.py but uses processes instead of threads.  A subpackage 'multiprocessing.dummy' has the same API but is a simple  wrapper for 'threading'.

### os.fork()函数

Unix/Linux操作系统提供了一个fork()系统调用, 调用一次，返回两次。 因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。

子进程永远返回0，而父进程返回创建的子进程ID。

有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，

常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。（注意是进程级别）

Python 的`os模块`封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：

```python

import os

print('Main Process : {} '.format(os.getpid()))

pid = os.fork() # 一次调用，两次返回

if pid == 0:
	print('I am child process {} and my parent is {}'.format(os.getpid(), os.getppid()))
else:
	print('I {} just created a child process {}'.format(os.getpid(), pid))

```


### multiprocessing.Process

`multiprocessing模块`提供了一个`Process类`来代表一个进程对象，对os.fork()进行了封装， 跨平台版本的多进程模块

创建子进程Process时，只需要传入一个执行函数和函数的参数，用start()方法启动，这样创建进程比os.fork()还要简单。

```python

from multiprocessing import Process
import os

# 子进程要执行的代码
def run_subproc(sub_name):
	print('Run child process {} {}'.format(sub_name, os.getpid()))


if __name__ == '__main__':

	print('Main process {}'.format(os.getpid()))

	for i in range(3):
		sub_name = 'test_{}'.format(i)
		p = Process(target=run_subproc, args=(sub_name,))
		p.start()
```

### multiprocessing.Pool

如果要启动大量的子进程，可以用进程池的方式批量创建子进程

```python

import os, time, random
from multiprocessing import Pool

def long_time_process(sub_name):
	print('Run child process {} {}, parent pid {} '.format(sub_name, os.getpid(), os.getppid()))
	
	start_ = time.time()
	time.sleep(random.random()*5)
	end = time.time()

	print('child process {} runs {} seconds.'.format(sub_name, (end-start_)))


if __name__=='__main__':
	print('Main Process {}'.format(os.getpid()))
			
	# # Pool类默认大小是CPU核数，因为最多同时执行CPU核数个进程，这是Pool有意设计的限制，
	# 当然，如果设置为30，也可以最多同时执行30个进程
	p = Pool(16) 
	for i in range(20):
		p.apply_async(long_time_process, args=(i,))
	print('Waiting for all subprocesses done...')

	p.close() # 调用close()之后就不能继续添加新的Process了

	p.join() # Pool对象调用join()方法会等待所有子进程执行完毕

	print('Done')
```



### subprocess模块

```python

import subprocess

r = subprocess.call(['nslookup','www.python.org'])

print('Exit code:',r)
```


### 进程间通信

Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。

我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据

```python

from multiprocessing import Process, Queue
import os, time, random

def process_write(queue):
	print('Process to write :', os.getpid())

	for value in range(20):
		print('Put {} to queue...'.format(value))
		queue.put(value)
		time.sleep(random.random()*5)

def process_read(queue):
	print('Process to read: ', os.getpid())

	while True:
		value = queue.get(True)
		print('Get {} from queue..'.format(value))


if __name__=='__main__':
	q = Queue()

	p_write = Process(target=process_write, args=(q,))
	p_read = Process(target=process_read, args=(q,))

	p_write.start()
	p_read.start()

	p_write.join() # 等待pw结束
	p_read.terminate() # pr进程里是死循环，无法等待其结束，只能强行终止

```