---
layout:     post
title:      科普一秒钟 / 图像分类
subtitle:   #副标题
date:       2019-4-5 				# 时间
author:     zhu.xinwei 		    	# 作者
header-img: img/post-bg-desk.jpg	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 交叉熵
    - DenseNet
    - 
---

单标签的图像分类问题
- 跨物种语义级别的图像分类: cifar10，相对容易，类间方差大、类内方差小
- 子类细粒度图像分类：加利福尼亚理工学院鸟类数据集CUB-2011，难度较大
- 实例级别图像分类：人脸识别


### 图像分类模型

##### MNIST与LeNet5

效果不如同一时期的SVM

3个卷积层 + 2个池化层：卷积核大小都是5x5
输入32x32x1: 6个5x5 conv --> pooling --> 16个5x5 conv --> pooling --> 120个5x5 conv --> 84 fc

##### ImageNet与AlexNet

在ImageNet发布早期，仍然是SVM和Boost为代表的分类方法占据优势，直到2012年AlexNet的出现；
AlexNet有一下特点：
- 网络比LeNet5更深，包括5个卷积层和3个全连接层；
- 使用Relu激活函数，收敛很快，解决了Sigmoid在网络较深时出现的梯度消失问题；
- 加入了Dropout层，防止过拟合；
- 使用剪切翻转等操作做数据增强，预测时使用水平翻转+5 crop操作，求10副图像平均值；
- 使用了LRN归一化层；

5个卷积层 + 3个全连接层: 卷积核大小有 11x11 5x5 3x3
> 输入224x224x3: 96个11x11 conv --> 256个5x5 conv --> 384个3x3 conv --> 384个3x3 conv --> 256个3x3 conv --> 4096 fc --> 4096 fc --> 1000 fc

2013年冠军 ZFNet: 利用反卷积技术，引入神经网络的可视化，对AlexNet进行简单的改进，如，使用了更小的卷积核和步长

2014年冠军 GoogLeNet： 通过将多个不同尺度的卷积核提取特征，然后进行融合,
22层怎么计算的：一个inception module先经过1x1 conv，然后再做其他尺度conv，所以算两层 conv，一共有9个inception conv，所以有18层，再加上开头三个卷积核，结尾一个FC连接，正好22层；
> 输入224x224x3: 7x7x64 conv -->1x1 conv --> 3x3x192 conv --> 两个 inception(1x1x64, 3x3x128, 5x5x32, maxpool 32) --> 五个 inception module --> 两个inception module

缺点：太复杂了，人工设计的痕迹太重了，扩展性一般

2014年亚军 VGG：全部使用3x3卷积核和2x2的最大池化核，用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）， VGG权重主要在FC层；
> 输入224x224x3: 连续两个 3x3x64 conv --> 连续两个 3x3x128 conv --> 连续三个 3x3x256 conv --> 连续三个 3x3x512 conv --> 连续三个 3x3x256 conv --> 3个 fc

2015年冠军 ResNet：在VGG基础上，加入更多的连续 conv 层，

创新点：
缺点：

34-layer plain:
输入224x224x3: 7x7x64 conv --> 连续6个 3x3x64 conv --> 连续8个 3x3x128 conv --> 连续12个 3x3x256 conv --> 连续6个 3x3x512 conv

2016年亚军： ResNeXt，101层的ResNeXt可以达到ResNet152的精度，复杂度只有后者的一半，核心思想是分组卷积，即，先将输入通道进行分组，经过若干并行分支的非线性变换，最后合并；

提高模型的准准确率角度：
- VGG、ResNet通过加深网络：将前一层的输入+当前层的激活值，然后再做非线性激活，作为当前层的输出；
- Inception通过加宽网络：先将输入分配到多路，然后每一路进行转换，最后再把所有支路的结果融合）
都会导致超参数量增加channels、filter size等；

相当于在说，Inception-ResNet和通道分组卷积网络，都只是ResNeXt这一范式的特殊形式而已，进一步说明了split-transform-merge的普遍性和有效性，

得益于精心设计的复杂的网络结构，ResNet-Inception v2可能效果会更好一点，但是ResNeXt的网络结构更简单，可以防止对于特定数据集的过拟合。而且更简单的网络意味着在用于自己的任务的时候，自定义和修改起来更简单。

Inception借鉴ResNet得到Inception-ResNet，而ResNet借鉴Inception得到了ResNeXt

2017年冠军 SENet：使用“特征重标定”的策略来对特征进行处理，通过学习获取每个特征通道的重要程度，根据重要性去降低或者提升相应的特征通道权重；

多标签分类问题、类别不均衡分类