---
layout:     post   				    # 使用的布局（不需要改）
title:     	深度学习 / 图像分类 / GoogLeNet 论文笔记
subtitle:      #副标题
date:       2018-9-18 				# 时间
author:     zhu.xinwei 		    	# 作者
header-img: img/post-bg-desk.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 图像分类
    - GoogLeNet
    - Inception v1
    - Inception v2
    - Inception v3
---

> 2014年, Christian Szegedy等人在一篇名为[Going deeper with convolutions](https://arxiv.org/pdf/1409.4842.pdf)的论文中首次提出GoogLeNet, 并取得了2014年ILSVRC比赛的冠军。 同年出现的还有VGG网络(ILSVRC亚军)。 VGG继承了LeNet以及AlexNet的一些框架结构，而GoogLeNet则做了更加大胆的网络结构尝试，虽然深度有22层，但大小却比AlexNet和VGG小很多，GoogLeNet参数为500万个，AlexNet参数个数是GoogLeNet的12倍，VGGNet参数又是AlexNet的3倍，因此在内存或计算资源有限时，GoogleNet是比较好的选择；从模型结果来看，GoogLeNet的性能却更加优越。 2014年，科研界诞生了两个影响至今的模型，而笔者刚刚读完[《灿烂千阳》](https://book.douban.com/subject/2143732/), 还在沉浸于那段不可宽恕的时代，不可能的友谊以及不可毁灭的爱。

> 小知识：GoogLeNet是谷歌（Google）研究出来的深度网络结构，为什么不叫“GoogleNet”，而叫“GoogLeNet”，据说是为了向“LeNet”致敬，因此取名为“GoogLeNet”

同年提出的 VGG 网络以及从 2012 年以来的 AlexNet(本质上就是扩展 LeNet 的深度，并应用一些 ReLU、Dropout 等技巧) 都遵循基本卷积网络的原型布局：一系列卷积层、最大池化层和激活层，最后还有一些全连接的分类层。VGG 的泛化性能非常好，常用于图像特征的抽取目标检测候选框生成等。VGG 最大的问题就在于参数数量，VGG-19 基本上是参数量最多的卷积网络架构。这一问题也是第一次提出 Inception 结构的 GoogLeNet 所重点关注的，它没有如同 VGG 那样大量使用全连接网络，因此参数量非常小。

要让神经网络更强大，两个思路，更深或者更宽，ResNet(2015年)走的路是做得更深，GoogLeNet(2014年)则走的变宽路线。


### Inception-V1 GoogLeNet

![](/img/cnn/inception_module_1.PNG)

Inception Module: 包含几种不同大小的卷积，即1x1卷积，3x3卷积和5x5卷积，还包括一个3x3的max pooling层。这些卷积层和pooling层得到的特征concat在一起作为最终的输出，也是下一个模块的输入。但是采用较大的卷积核计算复杂度较大，只能限制特征的channel数量。所以GoogLeNet采用了1x1卷积来进行优化，即先采用1x1卷积将特征的channel数降低，然后再进行前面所说的卷积。这种“瓶颈层”设计也是后面很多网络所常采用的，如ResNet网络。


```python
class Inception(nn.Module):

    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):
        super(Inception, self).__init__()

        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1) # BasicConv2d 将卷积,BN，ReLu进行了封装

        self.branch2 = nn.Sequential(
            BasicConv2d(in_channels, ch3x3red, kernel_size=1),
            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)
        )

        self.branch3 = nn.Sequential(
            BasicConv2d(in_channels, ch5x5red, kernel_size=1),
            BasicConv2d(ch5x5red, ch5x5, kernel_size=3, padding=1)
        )

        self.branch4 = nn.Sequential(
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),
            BasicConv2d(in_channels, pool_proj, kernel_size=1)
        )

    def forward(self, x):

        branch1 = self.branch1(x)
        branch2 = self.branch2(x)
        branch3 = self.branch3(x)
        branch4 = self.branch4(x)

        outputs = [branch1, branch2, branch3, branch4]
        return torch.cat(outputs, 1)

```


第一部分卷积 Stem部分

```python

        # 第一部分卷积
        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)
        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)
        self.conv2 = BasicConv2d(64, 64, kernel_size=1)
        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)
        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

```

中间Inception组件堆叠

```python

        # inception 组件
        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)
        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)
        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        # 
        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)
        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)
        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)
        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)
        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)
        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)

        # 
        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)
        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)


```

卷积层之后采用Global Average Pooling层，而不是全连接层，这有助于减少参数量，最近的分类网络也基本上是类似的思路。
```python

        x = self.avgpool(x)
        # N x 1024 x 1 x 1
        x = torch.flatten(x, 1)
        # N x 1024
        x = self.dropout(x)
        x = self.fc(x)

```

GoogLeNet整体数据流向
```python

class GoogLeNet(nn.Module):

    def __init__(self, num_classes=1000, aux_logits=True, transform_input=False, init_weights=True):
        super(GoogLeNet, self).__init__()
        self.aux_logits = aux_logits
        self.transform_input = transform_input

        # 第一部分卷积
        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)
        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)
        self.conv2 = BasicConv2d(64, 64, kernel_size=1)
        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)
        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        # inception 组件
        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)
        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)
        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)
        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)
        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)
        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)
        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)
        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)

        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)
        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)

        # if aux_logits:
        #     self.aux1 = InceptionAux(512, num_classes)
        #     self.aux2 = InceptionAux(528, num_classes)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(1024, num_classes)

        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        # if self.transform_input:
        #     x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5
        #     x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5
        #     x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5
        #     x = torch.cat((x_ch0, x_ch1, x_ch2), 1)

        # N x 3 x 224 x 224
        x = self.conv1(x)       # N x 64 x 112 x 112
        x = self.maxpool1(x)    # N x 64 x 56 x 56
        x = self.conv2(x)       # N x 64 x 56 x 56
        x = self.conv3(x)       # N x 192 x 56 x 56
        x = self.maxpool2(x)    # N x 192 x 28 x 28

        
        x = self.inception3a(x) # N x 256 x 28 x 28
        x = self.inception3b(x) # N x 480 x 28 x 28
        x = self.maxpool3(x)    # N x 480 x 14 x 14

        x = self.inception4a(x) # N x 512 x 14 x 14
        # if self.training and self.aux_logits:
        #     aux1 = self.aux1(x)
        x = self.inception4b(x) # N x 512 x 14 x 14
        x = self.inception4c(x) # N x 512 x 14 x 14
        x = self.inception4d(x) # N x 528 x 14 x 14
        # if self.training and self.aux_logits:
        #     aux2 = self.aux2(x)
        x = self.inception4e(x) # N x 832 x 14 x 14
        x = self.maxpool4(x)    # N x 832 x 7 x 7

        x = self.inception5a(x) # N x 832 x 7 x 7
        x = self.inception5b(x) # N x 1024 x 7 x 7
        

        x = self.avgpool(x)     # N x 1024 x 1 x 1
        x = torch.flatten(x, 1) # N x 1024
        x = self.dropout(x)
        x = self.fc(x)

        # N x 1000 (num_classes)
        if self.training and self.aux_logits:
            return _GoogLeNetOutputs(x, aux2, aux1)
        return x

```


### Inception-V2, BN-Inception

[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://proceedings.mlr.press/v37/ioffe15.pdf)

在Inception-v2网络，作者引入了BN层，所以Inception-v2其实是BN-Inception，这点Google在Inception-v4的paper中进行了说明。目前BN层已经成为了CNN网络最常用的一种策略，简单来说，就是对中间特征进行归一化。采用BN层后，一方面可以使用较大的学习速率，加快收敛速度，另外一方面，BN层具有正则化效应。

> 首先计算特征的mean和var，然后进行归一化，但是为了保证一定的可变度，增加了gamma和beta两个训练参数进行缩放和偏移。在训练过程，还要记录两个累积量：moving_mean和moving_var，它是每个训练step中batch的mean和var的指数加权移动平均数。在inference过程，不需要计算mean和var，而是使用训练过程中的累积量。这种训练和测试之间的差异性是BN层最被诟病的，所以后面有一系列的改进方法，如Group Norm等。


### Inception-V3

2015年，[Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)

Inception-v3引入的核心理念是“因子化”（Factorization），主要是将一些较大的卷积分解成几个较小的卷积。比如将一个5x5卷积分解成两个3x3卷积。 可以计算，采用5x5卷积，参数量是5x5=25，而两个3x3卷积的参数量是3x3+3x3=18，参数量减少了28%，但是两者效果是等价的（感受野）。

![](/img/cnn/inception_v3_factor_1.PNG)

```python
class InceptionB(nn.Module):

    def __init__(self, in_channels):
        super(InceptionB, self).__init__()
        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)

        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)
        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)
        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)

    def forward(self, x):
        branch3x3 = self.branch3x3(x)

        # 
        branch3x3dbl = self.branch3x3dbl_1(x)
        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)
        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)

        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)

        outputs = [branch3x3, branch3x3dbl, branch_pool]
        return torch.cat(outputs, 1)

```
另外的一个因子化，是将nxn的卷积分解成1xn和nx1卷积

![](/img/cnn/inception_v3_factor_2.PNG)


```python

class InceptionC(nn.Module):

    def __init__(self, in_channels, channels_7x7):
        super(InceptionC, self).__init__()
        self.branch1x1 = BasicConv2d(in_channels, 192, kernel_size=1)

        c7 = channels_7x7
        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=1)
        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))
        self.branch7x7_3 = BasicConv2d(c7, 192, kernel_size=(7, 1), padding=(3, 0))

        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=1)
        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))
        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))
        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))
        self.branch7x7dbl_5 = BasicConv2d(c7, 192, kernel_size=(1, 7), padding=(0, 3))

        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)

    def forward(self, x):
        branch1x1 = self.branch1x1(x)

        # 先经过一个1x1卷积，然后分别进行1x7和7x1卷积
        branch7x7 = self.branch7x7_1(x)
        branch7x7 = self.branch7x7_2(branch7x7)
        branch7x7 = self.branch7x7_3(branch7x7)

        branch7x7dbl = self.branch7x7dbl_1(x)
        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)
        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)
        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)
        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)

        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
        branch_pool = self.branch_pool(branch_pool)

        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]
        return torch.cat(outputs, 1)

```









[大话CNN经典模型：VGGNet](https://my.oschina.net/u/876354/blog/1634322)

[](https://my.oschina.net/u/876354/blog/1637819)


[](https://zhuanlan.zhihu.com/p/50754671)

[](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)